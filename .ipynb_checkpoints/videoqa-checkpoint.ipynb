{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import h5py\n",
    "import pytorch_lightning as pl\n",
    "import wandb\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import transformers\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "from DataLoader import VideoQADataModule, TVQADataModule\n",
    "import preprocess.msvd_text_prep as msvd_text_prep\n",
    "import preprocess.tgif_frameqa_text_prep as tgif_frameqa_text_prep\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# msvd_glove_data_module = VideoQADataModule('data','msvd-qa',batch_size=32,text_embedding_model='glove',num_workers=8)\n",
    "# msrvtt_glove_data_module = VideoQADataModule('data','msrvtt-qa',batch_size=32,text_embedding_model='glove',num_workers=8)\n",
    "# tgif_glove_data_module = VideoQADataModule('data','tgif-qa_frameqa',batch_size=32,text_embedding_model='glove',num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# msvd_bert_data_module = VideoQADataModule('data','msvd-qa',batch_size=32,text_embedding_model='bert',num_workers=8)\n",
    "msrvtt_bert_data_module = VideoQADataModule('data','msrvtt-qa',batch_size=32,text_embedding_model='bert',num_workers=8)\n",
    "# tgifqa_frameqa_bert_data_module = VideoQADataModule('data','tgif-qa_frameqa',batch_size=32,text_embedding_model='bert')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "## Defining the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import model.HCRN as HCRN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class HCRN_glove(pl.LightningModule):\n",
    "    def __init__(self,glove_matrix,lr,model_kwargs,optimizer = 'AdamW'):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.train_acc = pl.metrics.Accuracy()\n",
    "        self.valid_acc = pl.metrics.Accuracy()\n",
    "        self.test_acc = pl.metrics.Accuracy()\n",
    "        \n",
    "        glove_matrix = torch.FloatTensor(glove_matrix)\n",
    "        self.model = HCRN.HCRNNetworkGlove(**model_kwargs)\n",
    "        with torch.no_grad():\n",
    "            self.model.linguistic_input_unit.encoder_embed.weight.set_(glove_matrix)\n",
    "    \n",
    "    def forward(self,ans_candidates, ans_candidates_len, video_appearance_feat, video_motion_feat, question,\n",
    "                question_len):\n",
    "        return self.model(ans_candidates, ans_candidates_len, video_appearance_feat, video_motion_feat, question,\n",
    "                question_len)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        if(self.optimizer == 'Adam'):\n",
    "            optimizer = optim.Adam(self.parameters(), lr=self.lr)\n",
    "        elif(self.optimizer == 'AdamW'):\n",
    "            optimizer = optim.AdamW(self.parameters(), lr=self.lr)\n",
    "        else:\n",
    "            raise \"Optimizer not supported\"\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer,10,gamma=0.5)\n",
    "        return [optimizer],[scheduler]\n",
    "   \n",
    "    def training_step(self,batch,batch_idx):\n",
    "        _, _, answers, *batch_input = batch\n",
    "        logits = self(*batch_input)\n",
    "        loss = self.criterion(logits, answers)\n",
    "        acc = self.train_acc(logits,answers)\n",
    "        self.log('step_loss',loss,prog_bar = True,logger=False)\n",
    "        return {'loss': loss,'n_samples':len(answers)}\n",
    "    \n",
    "    def training_epoch_end(self, training_step_outputs):\n",
    "        loss=0\n",
    "        n_samples = 0\n",
    "        for step_out in training_step_outputs:\n",
    "            loss += step_out['loss']\n",
    "            n_samples += step_out['n_samples']\n",
    "        loss = loss/n_samples\n",
    "        self.log('train_loss',loss,logger=True)\n",
    "        self.log('train_acc',self.train_acc.compute(),logger=True)\n",
    "        \n",
    "    def validation_step(self,batch,batch_idx):\n",
    "        _, _, answers, *batch_input = batch\n",
    "        logits = self(*batch_input)\n",
    "        loss = self.criterion(logits, answers)\n",
    "        acc = self.valid_acc(logits,answers)\n",
    "        return {'val_loss': loss,'n_samples':len(answers)}\n",
    "    \n",
    "    def validation_epoch_end(self, val_step_outputs):\n",
    "        loss=0\n",
    "        n_samples = 0\n",
    "        for step_out in val_step_outputs:\n",
    "            loss += step_out['val_loss']\n",
    "            n_samples += step_out['n_samples']\n",
    "        loss = loss/n_samples\n",
    "        val_acc = self.valid_acc.compute()\n",
    "        self.log('val_acc',val_acc,prog_bar = True,logger=True)\n",
    "        self.log('val_loss',loss,logger=True)\n",
    "        \n",
    "    def test_step(self,batch,batch_idx):\n",
    "        _, _, answers, *batch_input = batch\n",
    "        logits = self(*batch_input).detach()\n",
    "        acc = self.test_acc(logits,answers)\n",
    "    \n",
    "    def test_epoch_end(self,test_step_outputs):\n",
    "        test_acc = self.test_acc.compute()\n",
    "        print(f\"The test accuracy is {test_acc}\")\n",
    "        self.log('test_acc',test_acc,logger=True)\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "## Recreating papers results on MSVD-QA, MSRVTT-QA, TGIF-QA_FrameQA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "### MSVD-QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 1\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': msvd_glove_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'word_dim': 300,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': msvd_glove_data_module.vocab\n",
    "    }\n",
    "model = HCRN_glove(\n",
    "    glove_matrix=msvd_glove_data_module.glove_matrix,\n",
    "    lr=0.0001,\n",
    "    model_kwargs=model_kwargs,\n",
    "    optimizer='Adam'\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/msvd/baseline',\n",
    "    filename='msvd-base-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "wandb_logger = WandbLogger(name='HCRN-MSVD-base',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,msvd_glove_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "### MSRVTT-QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 25\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': msrvtt_glove_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'word_dim': 300,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': msrvtt_glove_data_module.vocab\n",
    "    }\n",
    "model = HCRN_glove(\n",
    "    glove_matrix=msrvtt_glove_data_module.glove_matrix,\n",
    "    lr=0.0001, \n",
    "    model_kwargs=model_kwargs, \n",
    "    optimizer='Adam'\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/msrvtt/baseline',\n",
    "    filename='msrvtt-base-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "wandb_logger = WandbLogger(name='HCRN-MSRVTT-base',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,msrvtt_glove_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(verbose=False)\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "### TGIF-QA FrameQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 25\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': tgif_glove_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'word_dim': 300,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': tgif_glove_data_module.vocab\n",
    "    }\n",
    "model = HCRN_glove(\n",
    "    glove_matrix=tgif_glove_data_module.glove_matrix,\n",
    "    lr=0.0001, \n",
    "    model_kwargs=model_kwargs, \n",
    "    optimizer='Adam'\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/tgif-qa_frameqa/baseline',\n",
    "    filename='tgif-qa_frameqa-base-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "wandb_logger = WandbLogger(name='HCRN-MSRVTT-base',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,tgif_glove_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(verbose=False)\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "## Improving using AdamW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### MSVD-QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 15\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': msvd_glove_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'word_dim': 300,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': msvd_glove_data_module.vocab\n",
    "    }\n",
    "model = HCRN_glove(\n",
    "    glove_matrix=msvd_glove_data_module.glove_matrix,\n",
    "    lr=0.0001,\n",
    "    model_kwargs=model_kwargs,\n",
    "    optimizer='AdamW'\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/msvd/baseline',\n",
    "    filename='msvd-adamw-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "wandb_logger = WandbLogger(name='HCRN-MSVD-base',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,msvd_glove_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(verbose=False)\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### MSRVTT-QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 15\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': msrvtt_glove_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'word_dim': 300,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': msrvtt_glove_data_module.vocab\n",
    "    }\n",
    "model = HCRN_glove(\n",
    "    glove_matrix=msrvtt_glove_data_module.glove_matrix,\n",
    "    lr=0.0001, \n",
    "    model_kwargs=model_kwargs, \n",
    "    optimizer='AdamW'\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/msrvtt/baseline',\n",
    "    filename='msrvtt-adamw-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "wandb_logger = WandbLogger(name='HCRN-MSRVTT-base',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,msrvtt_glove_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(model,msrvtt_glove_data_module.test_dataloader())\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save('models_checkpoints/msrvtt/baseline/msrvtt-adamw-epoch=09-val_acc=0.35.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### TGIF-QA FrameQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 15\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': tgif_glove_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'word_dim': 300,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': tgif_glove_data_module.vocab\n",
    "    }\n",
    "model = HCRN_glove.load_from_checkpoint(\n",
    "    'models_checkpoints/tgif-qa_frameqa/baseline/tgif-qa_frameqa-adamW-epoch=07-val_acc=0.56.ckpt',\n",
    "    glove_matrix=tgif_glove_data_module.glove_matrix,\n",
    "    lr=0.0001, \n",
    "    model_kwargs=model_kwargs, \n",
    "    optimizer='AdamW'\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/tgif-qa_frameqa/baseline',\n",
    "    filename='tgif-qa_frameqa-base-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "wandb_logger = WandbLogger(name='HCRN-MSRVTT-base',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,tgif_glove_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(model,test_dataloaders = tgif_glove_data_module.test_dataloader())\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "## Create Bert Questions datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### MSVD-QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.read_json('data/msvd-qa/raw_questions/train_qa.json').to_csv('data/msvd-qa/raw_questions/train_qa.csv',sep= '\\t')\n",
    "pd.read_json('data/msvd-qa/raw_questions/val_qa.json').to_csv('data/msvd-qa/raw_questions/val_qa.csv',sep= '\\t')\n",
    "pd.read_json('data/msvd-qa/raw_questions/test_qa.json').to_csv('data/msvd-qa/raw_questions/test_qa.csv',sep= '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "msvd_text_prep.create_vocab('data/msvd-qa/raw_questions/train_qa.json',vocab_path='data/msvd-qa/bert_question_embedding/msvd-qa_vocab_bert.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "msvd_text_prep.process_questions(\n",
    "    train_csv ='data/msvd-qa/raw_questions/train_qa.csv', \n",
    "    val_csv = 'data/msvd-qa/raw_questions/val_qa.csv',\n",
    "    test_csv = 'data/msvd-qa/raw_questions/test_qa.csv',\n",
    "    fine_tune_out_path ='data/msvd-qa/bert_question_embedding/question_finetuned_model',\n",
    "    train_output = 'data/msvd-qa/bert_question_embedding/msvd-qa_train_questions.pt',\n",
    "    val_output = 'data/msvd-qa/bert_question_embedding/msvd-qa_val_questions.pt',\n",
    "    test_output = 'data/msvd-qa/bert_question_embedding/msvd-qa_test_questions.pt',\n",
    "    vocab_path='data/msvd-qa/bert_question_embedding/msvd-qa_vocab_bert.json'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### TGIFQA FrameQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "tgif_frameqa_text_prep.create_vocab('data/tgif-qa_frameqa/raw_questions/train_qa.csv',vocab_path='data/tgif-qa_frameqa/bert_question_embedding/tgif-qa_frameqa_vocab_bert.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "tgif_frameqa_text_prep.process_questions(\n",
    "    train_csv ='data/tgif-qa_frameqa/raw_questions/train_qa.csv', \n",
    "    val_csv = 'data/tgif-qa_frameqa/raw_questions/val_qa.csv',\n",
    "    test_csv = 'data/tgif-qa_frameqa/raw_questions/test_qa.csv',\n",
    "    fine_tune_out_path ='data/tgif-qa_frameqa/bert_question_embedding/question_finetuned_model',\n",
    "    train_output = 'data/tgif-qa_frameqa/bert_question_embedding/tgif-qa_frameqa_train_questions.pt',\n",
    "    val_output = 'data/tgif-qa_frameqa/bert_question_embedding/tgif-qa_frameqa_val_questions.pt',\n",
    "    test_output = 'data/tgif-qa_frameqa/bert_question_embedding/tgif-qa_frameqa_test_questions.pt',\n",
    "    vocab_path='data/tgif-qa_frameqa/bert_question_embedding/tgif-qa_frameqa_vocab_bert.json'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "## Bert text embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import model.HCRN as HCRN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class HCRNBert(pl.LightningModule):\n",
    "    def __init__(self, lr, model_kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.train_acc = pl.metrics.Accuracy()\n",
    "        self.valid_acc = pl.metrics.Accuracy()\n",
    "        self.test_acc = pl.metrics.Accuracy()\n",
    "        \n",
    "        self.model = HCRN.HCRNNetworkBert(**model_kwargs)\n",
    "        \n",
    "        self.bert_params = []\n",
    "        self.rest_params = []\n",
    "        for name, param in self.named_parameters():\n",
    "            if(name.startswith('model.linguistic_input_unit.bert')):\n",
    "                self.bert_params.append(param)\n",
    "            else:\n",
    "                self.rest_params.append(param)\n",
    "    \n",
    "    def forward(self,ans_candidates_tokens, ans_candidates_attention_mask, ans_candidates_token_type_ids, video_appearance_feat, video_motion_feat, question_tokens,question_attention_masks,question_token_type_ids):\n",
    "        return self.model(ans_candidates_tokens, ans_candidates_attention_mask, ans_candidates_token_type_ids, video_appearance_feat, video_motion_feat, question_tokens,question_attention_masks,question_token_type_ids)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer_model = optim.AdamW(self.rest_params, lr=self.lr)\n",
    "        optimizer_bert = optim.AdamW(self.bert_params, lr=1e-5)\n",
    "\n",
    "        return {'optimizer': optimizer_model},{'optimizer': optimizer_bert}\n",
    "   \n",
    "    def training_step(self,batch,batch_idx,optimizer_idx):\n",
    "        _, _, answers, *batch_input = batch\n",
    "        logits = self(*batch_input)\n",
    "        loss = self.criterion(logits, answers)\n",
    "        acc = self.train_acc(logits,answers)\n",
    "        self.log('step_loss',loss,prog_bar = True,logger=False)\n",
    "        return {'loss': loss,'n_samples':len(answers)}\n",
    "    \n",
    "    def training_epoch_end(self, training_step_outputs):\n",
    "        loss=0\n",
    "        n_samples = 0\n",
    "        for step_out in training_step_outputs[0]:\n",
    "            loss += step_out['loss']\n",
    "            n_samples += step_out['n_samples']\n",
    "        loss = loss/n_samples\n",
    "        self.log('train_loss',loss,logger=True)\n",
    "        self.log('train_acc',self.train_acc.compute(),logger=True)\n",
    "        \n",
    "    def validation_step(self,batch,batch_idx):\n",
    "        _, _, answers, *batch_input = batch\n",
    "        logits = self(*batch_input)\n",
    "        loss = self.criterion(logits, answers)\n",
    "        acc = self.valid_acc(logits,answers)\n",
    "        return {'val_loss': loss,'n_samples':len(answers)}\n",
    "    \n",
    "    def validation_epoch_end(self, val_step_outputs):\n",
    "        loss=0\n",
    "        n_samples = 0\n",
    "        for step_out in val_step_outputs:\n",
    "            loss += step_out['val_loss']\n",
    "            n_samples += step_out['n_samples']\n",
    "        loss = loss/n_samples\n",
    "        val_acc = self.valid_acc.compute()\n",
    "        self.log('val_acc',val_acc,prog_bar = True,logger=True)\n",
    "        self.log('val_loss',loss,logger=True)\n",
    "        \n",
    "    def test_step(self,batch,batch_idx):\n",
    "        _, _, answers, *batch_input = batch\n",
    "        logits = self(*batch_input)\n",
    "        acc = self.test_acc(logits,answers)\n",
    "    \n",
    "    def test_epoch_end(self,test_step_outputs):\n",
    "        test_acc = self.test_acc.compute()\n",
    "        print(f\"The test accuracy is {test_acc}\")\n",
    "        self.log('test_acc',test_acc,logger=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "### No training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "#### Bert uncased single layer embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"video-qa-hcrn-recvis\",name='bert fextract hf-model single layer embed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 25\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': msvd_bert_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': msvd_bert_data_module.vocab,\n",
    "        'transformer_path': 'bert-base-uncased',\n",
    "        'mult_embedding': False\n",
    "    }\n",
    "model = HCRNBert(\n",
    "    lr=0.0001,\n",
    "    model_kwargs=model_kwargs\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/tgif-qa_frameqa/bert',\n",
    "    filename='tgif-bert-pretrained-1layer-nograd-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "wandb_logger = WandbLogger(name='HCRN-MSVD-bert',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,msvd_bert_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(verbose=False)\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "#### 4 Last layers bert base uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"video-qa-hcrn-recvis\",name='bert fextract hf-model 4 layer embed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 25\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': msvd_bert_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': msvd_bert_data_module.vocab,\n",
    "        'transformer_path': 'bert-base-uncased',\n",
    "        'mult_embedding': True\n",
    "    }\n",
    "model = HCRNBert(\n",
    "    lr=0.0001,\n",
    "    model_kwargs=model_kwargs,\n",
    "    optimizer='AdamW'\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/tgif-qa_frameqa/bert',\n",
    "    filename='tgif-bert-pretrained-4layer-nograd-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "wandb_logger = WandbLogger(name='HCRN-MSVD-bert',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,msvd_bert_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(verbose=False)\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "#### Finetuned on questions 1 layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"video-qa-hcrn-recvis\",name='bert fextract question-tuned-model single layer embed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 25\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': msvd_bert_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': msvd_bert_data_module.vocab,\n",
    "        'transformer_path': 'data/tgif-qa_frameqa/bert_question_embedding/question_finetuned_model',\n",
    "        'mult_embedding': False\n",
    "    }\n",
    "model = HCRNBert(\n",
    "    lr=0.0001,\n",
    "    model_kwargs=model_kwargs,\n",
    "    optimizer='AdamW'\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/tgif-qa_frameqa/bert',\n",
    "    filename='tgif-bert-finetuned-1layer-nograd-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "wandb_logger = WandbLogger(name='HCRN-MSVD-bert',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,msvd_bert_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(verbose=False)\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "#### Finetuned on questions 4layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"video-qa-hcrn-recvis\",name='bert fextract question-tuned-model single layer embed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 25\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': msvd_bert_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': msvd_bert_data_module.vocab,\n",
    "        'transformer_path': 'data/tgif-qa_frameqa/bert_question_embedding/question_finetuned_model',\n",
    "        'mult_embedding': True\n",
    "    }\n",
    "model = HCRNBert(\n",
    "    lr=0.0001,\n",
    "    model_kwargs=model_kwargs,\n",
    "    optimizer='AdamW'\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/tgif-qa_frameqa/bert',\n",
    "    filename='tgif-bert-finetuned-4layer-nograd-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "wandb_logger = WandbLogger(name='HCRN-MSVD-bert',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,msvd_bert_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(verbose=False)\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "### Tune all MSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"video-qa-hcrn-recvis\",name='msvd bert train all hf-model pooler')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 15\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': msvd_bert_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': msvd_bert_data_module.vocab,\n",
    "        'transformer_path': 'bert-base-uncased',\n",
    "        'train_bert': 'All'\n",
    "    }\n",
    "model = HCRNBert(\n",
    "    lr=0.0001,\n",
    "    model_kwargs=model_kwargs,\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/msvd/bert',\n",
    "    filename='tgif-bert-pretrained-1layer-train-all-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "lr_logger_callback = pl.callbacks.LearningRateMonitor(logging_interval='step')\n",
    "wandb_logger = WandbLogger(name='HCRN-MSVD-bert',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc,lr_logger_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,msvd_bert_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test()\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "### Tune all MSRVTT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"video-qa-hcrn-recvis\",name='msrvtt bert train all hf-model pooler')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 15\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': msrvtt_bert_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': msrvtt_bert_data_module.vocab,\n",
    "        'transformer_path': 'bert-base-uncased',\n",
    "        'train_bert': 'All'\n",
    "    }\n",
    "model = HCRNBert(\n",
    "    lr=0.0001,\n",
    "    model_kwargs=model_kwargs,\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/msrvtt/bert',\n",
    "    filename='tgif-bert-pretrained-1layer-train-all-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "lr_logger_callback = pl.callbacks.LearningRateMonitor(logging_interval='step')\n",
    "wandb_logger = WandbLogger(name='HCRN-MSVD-bert',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc,lr_logger_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,msrvtt_bert_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test()\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "### Tune TGIF QA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "#### Train All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"video-qa-hcrn-recvis\",name='tgif-qa bert train all hf-model pooler')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 25\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': tgifqa_frameqa_bert_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': tgifqa_frameqa_bert_data_module.vocab,\n",
    "        'transformer_path': 'bert-base-uncased',\n",
    "        'train_bert': 'All'\n",
    "    }\n",
    "model = HCRNBert(\n",
    "    lr=0.0001,\n",
    "    model_kwargs=model_kwargs,\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/tgif-qa_frameqa/bert',\n",
    "    filename='tgif-bert-pretrained-1layer-train-all-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "lr_logger_callback = pl.callbacks.LearningRateMonitor(logging_interval='step')\n",
    "wandb_logger = WandbLogger(name='HCRN-MSVD-bert',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc,lr_logger_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,tgifqa_frameqa_bert_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(ckpt_path='models_checkpoints/tgif-qa_frameqa/bert/tgif-bert-pretrained-1layer-train-all-epoch=08-val_acc=0.55.ckpt',verbose=False)\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "#### Train 4 last layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"video-qa-hcrn-recvis\",name='tgif-qa bert train 4 last hf-model pooler')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 25\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': tgifqa_frameqa_bert_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': tgifqa_frameqa_bert_data_module.vocab,\n",
    "        'transformer_path': 'bert-base-uncased',\n",
    "        'train_bert': 'last-4'\n",
    "    }\n",
    "model = HCRNBert(\n",
    "    nb_train_steps = tgifqa_frameqa_bert_data_module.number_training_steps(),\n",
    "    lr=0.0001,\n",
    "    max_epochs=max_epochs,\n",
    "    model_kwargs=model_kwargs,\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/tgif-qa_frameqa/bert',\n",
    "    filename='tgif-bert-pretrained-1layer-train-all-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "lr_logger_callback = pl.callbacks.LearningRateMonitor(logging_interval='epoch')\n",
    "wandb_logger = WandbLogger(name='HCRN-MSVD-bert',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc,lr_logger_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,tgifqa_frameqa_bert_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(verbose=False)\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "#### Train 2 last layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"video-qa-hcrn-recvis\",name='tgif-qa bert train 4 last hf-model pooler')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 25\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': tgifqa_frameqa_bert_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': tgifqa_frameqa_bert_data_module.vocab,\n",
    "        'transformer_path': 'bert-base-uncased',\n",
    "        'train_bert': 'last-4'\n",
    "    }\n",
    "model = HCRNBert(\n",
    "    nb_train_steps = tgifqa_frameqa_bert_data_module.number_training_steps(),\n",
    "    lr=0.0001,\n",
    "    max_epochs=max_epochs,\n",
    "    model_kwargs=model_kwargs,\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/tgif-qa_frameqa/bert',\n",
    "    filename='tgif-bert-pretrained-1layer-train-all-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "lr_logger_callback = pl.callbacks.LearningRateMonitor(logging_interval='epoch')\n",
    "wandb_logger = WandbLogger(name='HCRN-MSVD-bert',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc,lr_logger_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,tgifqa_frameqa_bert_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(verbose=False)\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "## Roberta Text Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Train All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"video-qa-hcrn-recvis\",name='tgif-qa distillbert train all hf-model pooler')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 25\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': tgifqa_frameqa_bert_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': tgifqa_frameqa_bert_data_module.vocab,\n",
    "        'transformer_path': 'distilbert-base-uncased',\n",
    "        'train_bert': 'All'\n",
    "    }\n",
    "model = HCRNBert(\n",
    "    lr=0.0001,\n",
    "    model_kwargs=model_kwargs,\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/tgif-qa_frameqa/bert',\n",
    "    filename='tgif-distillbert-pretrained-1layer-train-all-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "lr_logger_callback = pl.callbacks.LearningRateMonitor(logging_interval='step')\n",
    "wandb_logger = WandbLogger(name='HCRN-MSVD-distillbert',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc,lr_logger_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,tgifqa_frameqa_bert_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(verbose=False)\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from transformers import DistilBertModel\n",
    "DistilBertModel.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "## Bert Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import model.HCRN as HCRN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class HCRNBertAblation(pl.LightningModule):\n",
    "    def __init__(self, lr, model_kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.train_acc = pl.metrics.Accuracy()\n",
    "        self.valid_acc = pl.metrics.Accuracy()\n",
    "        self.test_acc = pl.metrics.Accuracy()\n",
    "        \n",
    "        self.model = HCRN.HCRNNetworkBertAblation(**model_kwargs)\n",
    "        \n",
    "        self.bert_params = []\n",
    "        self.rest_params = []\n",
    "        for name, param in self.named_parameters():\n",
    "            if(name.startswith('model.linguistic_input_unit.bert')):\n",
    "                self.bert_params.append(param)\n",
    "            else:\n",
    "                self.rest_params.append(param)\n",
    "    \n",
    "    def forward(self,ans_candidates_tokens, ans_candidates_attention_mask, ans_candidates_token_type_ids, video_appearance_feat, video_motion_feat, question_tokens,question_attention_masks,question_token_type_ids):\n",
    "        return self.model(ans_candidates_tokens, ans_candidates_attention_mask, ans_candidates_token_type_ids, video_appearance_feat, video_motion_feat, question_tokens,question_attention_masks,question_token_type_ids)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer_model = optim.AdamW(self.rest_params, lr=self.lr)\n",
    "        optimizer_bert = optim.AdamW(self.bert_params, lr=1e-5)\n",
    "        return {'optimizer': optimizer_model},{'optimizer': optimizer_bert}\n",
    "   \n",
    "    def training_step(self,batch,batch_idx,optimizer_idx):\n",
    "        _, _, answers, *batch_input = batch\n",
    "        logits = self(*batch_input)\n",
    "        loss = self.criterion(logits, answers)\n",
    "        acc = self.train_acc(logits,answers)\n",
    "        self.log('step_loss',loss,prog_bar = True,logger=False)\n",
    "        return {'loss': loss,'n_samples':len(answers)}\n",
    "    \n",
    "    def training_epoch_end(self, training_step_outputs):\n",
    "        loss=0\n",
    "        n_samples = 0\n",
    "        for step_out in training_step_outputs[0]:\n",
    "            loss += step_out['loss']\n",
    "            n_samples += step_out['n_samples']\n",
    "        loss = loss/n_samples\n",
    "        self.log('train_loss',loss,logger=True)\n",
    "        self.log('train_acc',self.train_acc.compute(),logger=True)\n",
    "        \n",
    "    def validation_step(self,batch,batch_idx):\n",
    "        _, _, answers, *batch_input = batch\n",
    "        logits = self(*batch_input)\n",
    "        loss = self.criterion(logits, answers)\n",
    "        acc = self.valid_acc(logits,answers)\n",
    "        return {'val_loss': loss,'n_samples':len(answers)}\n",
    "    \n",
    "    def validation_epoch_end(self, val_step_outputs):\n",
    "        loss=0\n",
    "        n_samples = 0\n",
    "        for step_out in val_step_outputs:\n",
    "            loss += step_out['val_loss']\n",
    "            n_samples += step_out['n_samples']\n",
    "        loss = loss/n_samples\n",
    "        val_acc = self.valid_acc.compute()\n",
    "        self.log('val_acc',val_acc,prog_bar = True,logger=True)\n",
    "        self.log('val_loss',loss,logger=True)\n",
    "        \n",
    "    def test_step(self,batch,batch_idx):\n",
    "        _, _, answers, *batch_input = batch\n",
    "        logits = self(*batch_input)\n",
    "        acc = self.test_acc(logits,answers)\n",
    "    \n",
    "    def test_epoch_end(self,test_step_outputs):\n",
    "        test_acc = self.test_acc.compute()\n",
    "        print(f\"The test accuracy is {test_acc}\")\n",
    "        self.log('test_acc',test_acc,logger=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "### MSVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Motion Ablation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "##### Full Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"video-qa-hcrn-recvis\",name='msvd-qa bert train all hf-model pooler no-motion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 15\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': msvd_bert_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': msvd_bert_data_module.vocab,\n",
    "        'transformer_path': 'bert-base-uncased',\n",
    "        'train_bert': 'All',\n",
    "        'ablated_features':['clip_motion','video_motion']\n",
    "    }\n",
    "model = HCRNBertAblation(\n",
    "    lr=0.0001,\n",
    "    model_kwargs=model_kwargs,\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/msvd/bert',\n",
    "    filename='tgif-bert-pretrained-1layer-train-all-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "lr_logger_callback = pl.callbacks.LearningRateMonitor(logging_interval='step')\n",
    "wandb_logger = WandbLogger(name='HCRN-MSVD-bert',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc,lr_logger_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,msvd_bert_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(verbose=False)\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "##### Video level Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"video-qa-hcrn-recvis\",name='msvd bert train all hf-model pooler no-video-motion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 15\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': msvd_bert_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': msvd_bert_data_module.vocab,\n",
    "        'transformer_path': 'bert-base-uncased',\n",
    "        'train_bert': 'All',\n",
    "        'ablated_features':['video_motion']\n",
    "    }\n",
    "model = HCRNBertAblation(\n",
    "    lr=0.0001,\n",
    "    model_kwargs=model_kwargs,\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/msvd/bert',\n",
    "    filename='tgif-bert-pretrained-1layer-train-all-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "lr_logger_callback = pl.callbacks.LearningRateMonitor(logging_interval='step')\n",
    "wandb_logger = WandbLogger(name='HCRN-MSVD-bert',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc,lr_logger_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,msvd_bert_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(verbose=False)\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "##### Clip level Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"video-qa-hcrn-recvis\",name='msvd bert train all hf-model pooler no-clip-motion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 15\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': msvd_bert_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': msvd_bert_data_module.vocab,\n",
    "        'transformer_path': 'bert-base-uncased',\n",
    "        'train_bert': 'All',\n",
    "        'ablated_features':['clip_motion']\n",
    "    }\n",
    "model = HCRNBertAblation(\n",
    "    lr=0.0001,\n",
    "    model_kwargs=model_kwargs,\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/msvd/bert',\n",
    "    filename='tgif-bert-pretrained-1layer-train-all-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "lr_logger_callback = pl.callbacks.LearningRateMonitor(logging_interval='step')\n",
    "wandb_logger = WandbLogger(name='HCRN-MSVD-bert',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc,lr_logger_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,msvd_bert_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(verbose=False)\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Question Ablation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "###### Full Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"video-qa-hcrn-recvis\",name='msvd bert train all hf-model pooler no-question-features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 15\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': msvd_bert_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': msvd_bert_data_module.vocab,\n",
    "        'transformer_path': 'bert-base-uncased',\n",
    "        'train_bert': 'All',\n",
    "        'ablated_features':['clip_question','video_question']\n",
    "    }\n",
    "model = HCRNBertAblation(\n",
    "    lr=0.0001,\n",
    "    model_kwargs=model_kwargs,\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/msvd/bert',\n",
    "    filename='tgif-bert-pretrained-1layer-train-all-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "lr_logger_callback = pl.callbacks.LearningRateMonitor(logging_interval='step')\n",
    "wandb_logger = WandbLogger(name='HCRN-MSVD-bert',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc,lr_logger_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,msvd_bert_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(verbose=False)\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "##### Video level Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"video-qa-hcrn-recvis\",name='msvd train all hf-model pooler no-video-question-features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 15\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': msvd_bert_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': msvd_bert_data_module.vocab,\n",
    "        'transformer_path': 'bert-base-uncased',\n",
    "        'train_bert': 'All',\n",
    "        'ablated_features':['video_question']\n",
    "    }\n",
    "model = HCRNBertAblation(\n",
    "    lr=0.0001,\n",
    "    model_kwargs=model_kwargs,\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/msvd/bert',\n",
    "    filename='tgif-bert-pretrained-1layer-train-all-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "lr_logger_callback = pl.callbacks.LearningRateMonitor(logging_interval='step')\n",
    "wandb_logger = WandbLogger(name='HCRN-MSVD-bert',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc,lr_logger_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,msvd_bert_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(verbose=False)\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "##### Clip level Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"video-qa-hcrn-recvis\",name='msvd bert train all hf-model pooler no-clip-question-features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 15\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': msvd_bert_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': msvd_bert_data_module.vocab,\n",
    "        'transformer_path': 'bert-base-uncased',\n",
    "        'train_bert': 'All',\n",
    "        'ablated_features':['clip_question']\n",
    "    }\n",
    "model = HCRNBertAblation(\n",
    "    lr=0.0001,\n",
    "    model_kwargs=model_kwargs,\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/msvd/bert',\n",
    "    filename='tgif-bert-pretrained-1layer-train-all-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "lr_logger_callback = pl.callbacks.LearningRateMonitor(logging_interval='step')\n",
    "wandb_logger = WandbLogger(name='HCRN-MSVD-bert',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc,lr_logger_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,msvd_bert_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(verbose=False)\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### No visual features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "##### No Visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"video-qa-hcrn-recvis\",name='msvd bert train all hf-model pooler no-visual-features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 15\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': msvd_bert_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': msvd_bert_data_module.vocab,\n",
    "        'transformer_path': 'bert-base-uncased',\n",
    "        'train_bert': 'All',\n",
    "        'ablated_features':['clip_motion','video_motion','video_appearance_ablation']\n",
    "    }\n",
    "model = HCRNBertAblation(\n",
    "    lr=0.0001,\n",
    "    model_kwargs=model_kwargs,\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/msvd/bert',\n",
    "    filename='tgif-bert-pretrained-1layer-train-all-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "lr_logger_callback = pl.callbacks.LearningRateMonitor(logging_interval='step')\n",
    "wandb_logger = WandbLogger(name='HCRN-MSVD-bert',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc,lr_logger_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,msvd_bert_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(verbose=False)\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "##### No appearance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"video-qa-hcrn-recvis\",name='msvd bert train all hf-model pooler no-appearance-features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 15\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': msvd_bert_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': msvd_bert_data_module.vocab,\n",
    "        'transformer_path': 'bert-base-uncased',\n",
    "        'train_bert': 'All',\n",
    "        'ablated_features':['video_appearance_ablation']\n",
    "    }\n",
    "model = HCRNBertAblation(\n",
    "    lr=0.0001,\n",
    "    model_kwargs=model_kwargs,\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/msvd/bert',\n",
    "    filename='tgif-bert-pretrained-1layer-train-all-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "lr_logger_callback = pl.callbacks.LearningRateMonitor(logging_interval='step')\n",
    "wandb_logger = WandbLogger(name='HCRN-MSVD-bert',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc,lr_logger_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,msvd_bert_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(verbose=False)\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### MSRVTT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Motion Ablation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "##### Full Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"video-qa-hcrn-recvis\",name='msrvtt bert train all hf-model pooler no-motion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 15\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': msrvtt_bert_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': msrvtt_bert_data_module.vocab,\n",
    "        'transformer_path': 'bert-base-uncased',\n",
    "        'train_bert': 'All',\n",
    "        'ablated_features':['clip_motion','video_motion']\n",
    "    }\n",
    "model = HCRNBertAblation(\n",
    "    lr=0.0001,\n",
    "    model_kwargs=model_kwargs,\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/msrvtt/bert',\n",
    "    filename='tgif-bert-pretrained-1layer-train-all-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "lr_logger_callback = pl.callbacks.LearningRateMonitor(logging_interval='step')\n",
    "wandb_logger = WandbLogger(name='HCRN-MSVD-bert',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc,lr_logger_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,msrvtt_bert_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(verbose=False)\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "##### Video level Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"video-qa-hcrn-recvis\",name='msrvtt bert train all hf-model pooler no-video-motion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 15\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': msrvtt_bert_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': msrvtt_bert_data_module.vocab,\n",
    "        'transformer_path': 'bert-base-uncased',\n",
    "        'train_bert': 'All',\n",
    "        'ablated_features':['video_motion']\n",
    "    }\n",
    "model = HCRNBertAblation(\n",
    "    lr=0.0001,\n",
    "    model_kwargs=model_kwargs,\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/msrvtt/bert',\n",
    "    filename='tgif-bert-pretrained-1layer-train-all-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "lr_logger_callback = pl.callbacks.LearningRateMonitor(logging_interval='step')\n",
    "wandb_logger = WandbLogger(name='HCRN-MSVD-bert',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc,lr_logger_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,msrvtt_bert_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(verbose=False)\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "##### Clip level Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"video-qa-hcrn-recvis\",name='msrvtt bert train all hf-model pooler no-clip-motion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 15\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': msrvtt_bert_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': msrvtt_bert_data_module.vocab,\n",
    "        'transformer_path': 'bert-base-uncased',\n",
    "        'train_bert': 'All',\n",
    "        'ablated_features':['clip_motion']\n",
    "    }\n",
    "model = HCRNBertAblation(\n",
    "    lr=0.0001,\n",
    "    model_kwargs=model_kwargs,\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/msrvtt/bert',\n",
    "    filename='tgif-bert-pretrained-1layer-train-all-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "lr_logger_callback = pl.callbacks.LearningRateMonitor(logging_interval='step')\n",
    "wandb_logger = WandbLogger(name='HCRN-MSVD-bert',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc,lr_logger_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,msrvtt_bert_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(verbose=False)\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Question Ablation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "###### Full Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"video-qa-hcrn-recvis\",name='msrvtt bert train all hf-model pooler no-question-features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 15\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': msrvtt_bert_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': msrvtt_bert_data_module.vocab,\n",
    "        'transformer_path': 'bert-base-uncased',\n",
    "        'train_bert': 'All',\n",
    "        'ablated_features':['clip_question','video_question']\n",
    "    }\n",
    "model = HCRNBertAblation(\n",
    "    lr=0.0001,\n",
    "    model_kwargs=model_kwargs,\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/msrvtt/bert',\n",
    "    filename='tgif-bert-pretrained-1layer-train-all-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "lr_logger_callback = pl.callbacks.LearningRateMonitor(logging_interval='step')\n",
    "wandb_logger = WandbLogger(name='HCRN-MSVD-bert',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc,lr_logger_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,msrvtt_bert_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(verbose=False)\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "##### Video level Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"video-qa-hcrn-recvis\",name='msrvtt train all hf-model pooler no-video-question-features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 15\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': msrvtt_bert_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': msrvtt_bert_data_module.vocab,\n",
    "        'transformer_path': 'bert-base-uncased',\n",
    "        'train_bert': 'All',\n",
    "        'ablated_features':['video_question']\n",
    "    }\n",
    "model = HCRNBertAblation(\n",
    "    lr=0.0001,\n",
    "    model_kwargs=model_kwargs,\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/msrvtt/bert',\n",
    "    filename='tgif-bert-pretrained-1layer-train-all-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "lr_logger_callback = pl.callbacks.LearningRateMonitor(logging_interval='step')\n",
    "wandb_logger = WandbLogger(name='HCRN-MSVD-bert',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc,lr_logger_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,msrvtt_bert_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(verbose=False)\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "##### Clip level Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"video-qa-hcrn-recvis\",name='msrvtt bert train all hf-model pooler no-clip-question-features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 15\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': msrvtt_bert_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': msrvtt_bert_data_module.vocab,\n",
    "        'transformer_path': 'bert-base-uncased',\n",
    "        'train_bert': 'All',\n",
    "        'ablated_features':['clip_question']\n",
    "    }\n",
    "model = HCRNBertAblation(\n",
    "    lr=0.0001,\n",
    "    model_kwargs=model_kwargs,\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/msrvtt/bert',\n",
    "    filename='tgif-bert-pretrained-1layer-train-all-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "lr_logger_callback = pl.callbacks.LearningRateMonitor(logging_interval='step')\n",
    "wandb_logger = WandbLogger(name='HCRN-MSVD-bert',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc,lr_logger_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,msrvtt_bert_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(verbose=False)\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### No visual features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "##### No Visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"video-qa-hcrn-recvis\",name='msrvtt bert train all hf-model pooler no-visual-features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 15\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': msrvtt_bert_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': msrvtt_bert_data_module.vocab,\n",
    "        'transformer_path': 'bert-base-uncased',\n",
    "        'train_bert': 'All',\n",
    "        'ablated_features':['clip_motion','video_motion','video_appearance_ablation']\n",
    "    }\n",
    "model = HCRNBertAblation(\n",
    "    lr=0.0001,\n",
    "    model_kwargs=model_kwargs,\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/msrvtt/bert',\n",
    "    filename='tgif-bert-pretrained-1layer-train-all-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "lr_logger_callback = pl.callbacks.LearningRateMonitor(logging_interval='step')\n",
    "wandb_logger = WandbLogger(name='HCRN-MSVD-bert',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc,lr_logger_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,msrvtt_bert_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(verbose=False)\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "##### No appearance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"video-qa-hcrn-recvis\",name='msrvtt bert train all hf-model pooler no-appearance-features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 15\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': msrvtt_bert_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': msrvtt_bert_data_module.vocab,\n",
    "        'transformer_path': 'bert-base-uncased',\n",
    "        'train_bert': 'All',\n",
    "        'ablated_features':['video_appearance_ablation']\n",
    "    }\n",
    "model = HCRNBertAblation(\n",
    "    lr=0.0001,\n",
    "    model_kwargs=model_kwargs,\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/msrvtt/bert',\n",
    "    filename='tgif-bert-pretrained-1layer-train-all-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "lr_logger_callback = pl.callbacks.LearningRateMonitor(logging_interval='step')\n",
    "wandb_logger = WandbLogger(name='HCRN-MSVD-bert',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc,lr_logger_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,msrvtt_bert_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(verbose=False)\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### TGIF-QA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Motion Ablation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "##### Full Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"video-qa-hcrn-recvis\",name='tgif-qa bert train all hf-model pooler no-motion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 15\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': tgifqa_frameqa_bert_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': tgifqa_frameqa_bert_data_module.vocab,\n",
    "        'transformer_path': 'bert-base-uncased',\n",
    "        'train_bert': 'All',\n",
    "        'ablated_features':['clip_motion','video_motion']\n",
    "    }\n",
    "model = HCRNBertAblation(\n",
    "    lr=0.0001,\n",
    "    model_kwargs=model_kwargs,\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/tgif-qa_frameqa/bert',\n",
    "    filename='tgif-bert-pretrained-1layer-train-all-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "lr_logger_callback = pl.callbacks.LearningRateMonitor(logging_interval='step')\n",
    "wandb_logger = WandbLogger(name='HCRN-MSVD-bert',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc,lr_logger_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,tgifqa_frameqa_bert_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(verbose=False)\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "##### Video level Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"video-qa-hcrn-recvis\",name='tgif-qa bert train all hf-model pooler no-video-motion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 15\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': tgifqa_frameqa_bert_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': tgifqa_frameqa_bert_data_module.vocab,\n",
    "        'transformer_path': 'bert-base-uncased',\n",
    "        'train_bert': 'All',\n",
    "        'ablated_features':['video_motion']\n",
    "    }\n",
    "model = HCRNBertAblation(\n",
    "    lr=0.0001,\n",
    "    model_kwargs=model_kwargs,\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/tgif-qa_frameqa/bert',\n",
    "    filename='tgif-bert-pretrained-1layer-train-all-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "lr_logger_callback = pl.callbacks.LearningRateMonitor(logging_interval='step')\n",
    "wandb_logger = WandbLogger(name='HCRN-MSVD-bert',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc,lr_logger_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,tgifqa_frameqa_bert_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(verbose=False)\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "##### Clip level Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"video-qa-hcrn-recvis\",name='tgif-qa bert train all hf-model pooler no-clip-motion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 15\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': tgifqa_frameqa_bert_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': tgifqa_frameqa_bert_data_module.vocab,\n",
    "        'transformer_path': 'bert-base-uncased',\n",
    "        'train_bert': 'All',\n",
    "        'ablated_features':['clip_motion']\n",
    "    }\n",
    "model = HCRNBertAblation(\n",
    "    lr=0.0001,\n",
    "    model_kwargs=model_kwargs,\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/tgif-qa_frameqa/bert',\n",
    "    filename='tgif-bert-pretrained-1layer-train-all-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "lr_logger_callback = pl.callbacks.LearningRateMonitor(logging_interval='step')\n",
    "wandb_logger = WandbLogger(name='HCRN-MSVD-bert',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc,lr_logger_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,tgifqa_frameqa_bert_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(verbose=False)\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Question Ablation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "###### Full Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"video-qa-hcrn-recvis\",name='tgif-qa bert train all hf-model pooler no-question-features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 15\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': tgifqa_frameqa_bert_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': tgifqa_frameqa_bert_data_module.vocab,\n",
    "        'transformer_path': 'bert-base-uncased',\n",
    "        'train_bert': 'All',\n",
    "        'ablated_features':['clip_question','video_question']\n",
    "    }\n",
    "model = HCRNBertAblation(\n",
    "    lr=0.0001,\n",
    "    model_kwargs=model_kwargs,\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/tgif-qa_frameqa/bert',\n",
    "    filename='tgif-bert-pretrained-1layer-train-all-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "lr_logger_callback = pl.callbacks.LearningRateMonitor(logging_interval='step')\n",
    "wandb_logger = WandbLogger(name='HCRN-MSVD-bert',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc,lr_logger_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,tgifqa_frameqa_bert_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(verbose=False)\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "##### Video level Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"video-qa-hcrn-recvis\",name='tgif-qa bert train all hf-model pooler no-video-question-features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 15\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': tgifqa_frameqa_bert_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': tgifqa_frameqa_bert_data_module.vocab,\n",
    "        'transformer_path': 'bert-base-uncased',\n",
    "        'train_bert': 'All',\n",
    "        'ablated_features':['video_question']\n",
    "    }\n",
    "model = HCRNBertAblation(\n",
    "    lr=0.0001,\n",
    "    model_kwargs=model_kwargs,\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/tgif-qa_frameqa/bert',\n",
    "    filename='tgif-bert-pretrained-1layer-train-all-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "lr_logger_callback = pl.callbacks.LearningRateMonitor(logging_interval='step')\n",
    "wandb_logger = WandbLogger(name='HCRN-MSVD-bert',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc,lr_logger_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,tgifqa_frameqa_bert_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(verbose=False)\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "##### Clip level Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"video-qa-hcrn-recvis\",name='tgif-qa bert train all hf-model pooler no-clip-question-features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 15\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': tgifqa_frameqa_bert_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': tgifqa_frameqa_bert_data_module.vocab,\n",
    "        'transformer_path': 'bert-base-uncased',\n",
    "        'train_bert': 'All',\n",
    "        'ablated_features':['clip_question']\n",
    "    }\n",
    "model = HCRNBertAblation(\n",
    "    lr=0.0001,\n",
    "    model_kwargs=model_kwargs,\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/tgif-qa_frameqa/bert',\n",
    "    filename='tgif-bert-pretrained-1layer-train-all-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "lr_logger_callback = pl.callbacks.LearningRateMonitor(logging_interval='step')\n",
    "wandb_logger = WandbLogger(name='HCRN-MSVD-bert',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc,lr_logger_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,tgifqa_frameqa_bert_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(verbose=False)\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### No visual features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "##### No Visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"video-qa-hcrn-recvis\",name='tgif-qa bert train all hf-model pooler no-visual-features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 15\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': tgifqa_frameqa_bert_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': tgifqa_frameqa_bert_data_module.vocab,\n",
    "        'transformer_path': 'bert-base-uncased',\n",
    "        'train_bert': 'All',\n",
    "        'ablated_features':['clip_motion','video_motion','video_appearance_ablation']\n",
    "    }\n",
    "model = HCRNBertAblation(\n",
    "    lr=0.0001,\n",
    "    model_kwargs=model_kwargs,\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/tgif-qa_frameqa/bert',\n",
    "    filename='tgif-bert-pretrained-1layer-train-all-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "lr_logger_callback = pl.callbacks.LearningRateMonitor(logging_interval='step')\n",
    "wandb_logger = WandbLogger(name='HCRN-MSVD-bert',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc,lr_logger_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,tgifqa_frameqa_bert_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(verbose=False)\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "##### No appearance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"video-qa-hcrn-recvis\",name='tgif-qa bert train all hf-model pooler no-appearance-features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 15\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': tgifqa_frameqa_bert_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': tgifqa_frameqa_bert_data_module.vocab,\n",
    "        'transformer_path': 'bert-base-uncased',\n",
    "        'train_bert': 'All',\n",
    "        'ablated_features':['video_appearance_ablation']\n",
    "    }\n",
    "model = HCRNBertAblation(\n",
    "    lr=0.0001,\n",
    "    model_kwargs=model_kwargs,\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/tgif-qa_frameqa/bert',\n",
    "    filename='tgif-bert-pretrained-1layer-train-all-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "lr_logger_callback = pl.callbacks.LearningRateMonitor(logging_interval='step')\n",
    "wandb_logger = WandbLogger(name='HCRN-MSVD-bert',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc,lr_logger_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,tgifqa_frameqa_bert_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(verbose=False)\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "## TVQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import model.HCRN as HCRN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class HCRNSubtitles(pl.LightningModule):\n",
    "    def __init__(self, lr, model_kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.train_acc = pl.metrics.Accuracy()\n",
    "        self.valid_acc = pl.metrics.Accuracy()\n",
    "        self.test_acc = pl.metrics.Accuracy()\n",
    "        \n",
    "        self.model = HCRN.HCRNNetworkTVQA(**model_kwargs)\n",
    "        \n",
    "        self.bert_params = []\n",
    "        self.rest_params = []\n",
    "        for name, param in self.named_parameters():\n",
    "            if(name.startswith('model.linguistic_input_unit.bert')):\n",
    "                self.bert_params.append(param)\n",
    "            else:\n",
    "                self.rest_params.append(param)\n",
    "    \n",
    "    def forward(self,ans_candidates_tokens, ans_candidates_attention_mask, ans_candidates_token_type_ids,\n",
    "                video_appearance_feat, question_tokens,question_attention_masks,question_token_type_ids,\n",
    "               subtitles_tokens, subtitles_attention_mask, subtitles_token_type_ids):\n",
    "        return self.model(ans_candidates_tokens, ans_candidates_attention_mask,\n",
    "                          ans_candidates_token_type_ids, video_appearance_feat,\n",
    "                          question_tokens,question_attention_masks,question_token_type_ids,\n",
    "                         subtitles_tokens,subtitles_attention_mask, subtitles_token_type_ids)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer_model = optim.AdamW(self.rest_params, lr=self.lr)\n",
    "        optimizer_bert = optim.AdamW(self.bert_params, lr=1e-5)\n",
    "\n",
    "        return {'optimizer': optimizer_model},{'optimizer': optimizer_bert}\n",
    "   \n",
    "    def training_step(self,batch,batch_idx,optimizer_idx):\n",
    "        _, _, answers, *batch_input = batch\n",
    "        logits = self(*batch_input)\n",
    "        loss = self.criterion(logits, answers)\n",
    "        acc = self.train_acc(logits,answers)\n",
    "        self.log('step_loss',loss,prog_bar = True,logger=False)\n",
    "        return {'loss': loss,'n_samples':len(answers)}\n",
    "    \n",
    "    def training_epoch_end(self, training_step_outputs):\n",
    "        loss=0\n",
    "        n_samples = 0\n",
    "        for step_out in training_step_outputs[0]:\n",
    "            loss += step_out['loss']\n",
    "            n_samples += step_out['n_samples']\n",
    "        loss = loss/n_samples\n",
    "        self.log('train_loss',loss,logger=True)\n",
    "        self.log('train_acc',self.train_acc.compute(),logger=True)\n",
    "        \n",
    "    def validation_step(self,batch,batch_idx):\n",
    "        _, _, answers, *batch_input = batch\n",
    "        logits = self(*batch_input)\n",
    "        loss = self.criterion(logits, answers)\n",
    "        acc = self.valid_acc(logits,answers)\n",
    "        return {'val_loss': loss,'n_samples':len(answers)}\n",
    "    \n",
    "    def validation_epoch_end(self, val_step_outputs):\n",
    "        loss=0\n",
    "        n_samples = 0\n",
    "        for step_out in val_step_outputs:\n",
    "            loss += step_out['val_loss']\n",
    "            n_samples += step_out['n_samples']\n",
    "        loss = loss/n_samples\n",
    "        val_acc = self.valid_acc.compute()\n",
    "        self.log('val_acc',val_acc,prog_bar = True,logger=True)\n",
    "        self.log('val_loss',loss,logger=True)\n",
    "        \n",
    "    def test_step(self,batch,batch_idx):\n",
    "        _, _, answers, *batch_input = batch\n",
    "        logits = self(*batch_input)\n",
    "        acc = self.test_acc(logits,answers)\n",
    "    \n",
    "    def test_epoch_end(self,test_step_outputs):\n",
    "        test_acc = self.test_acc.compute()\n",
    "        print(f\"The test accuracy is {test_acc}\")\n",
    "        self.log('test_acc',test_acc,logger=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "tvqa_bert_data_module = TVQADataModule('data','tvqa',batch_size=24,text_embedding_model='distilbert',num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnicolas-dufour\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.14 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.12<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">tvqa subtitles pre conditioning bert </strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/nicolas-dufour/video-qa-hcrn-recvis\" target=\"_blank\">https://wandb.ai/nicolas-dufour/video-qa-hcrn-recvis</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/nicolas-dufour/video-qa-hcrn-recvis/runs/18elcdfc\" target=\"_blank\">https://wandb.ai/nicolas-dufour/video-qa-hcrn-recvis/runs/18elcdfc</a><br/>\n",
       "                Run data is saved locally in <code>/home/jupyter/video-qa-recvis/wandb/run-20210123_105721-18elcdfc</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1>Run(18elcdfc)</h1><p></p><iframe src=\"https://wandb.ai/nicolas-dufour/video-qa-hcrn-recvis/runs/18elcdfc\" style=\"border:none;width:100%;height:400px\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f8197290f90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"video-qa-hcrn-recvis\",name='tvqa subtitles pre conditioning bert ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: Checkpoint directory models_checkpoints/tgif-qa_frameqa/bert exists and is not empty.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 10\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': tvqa_bert_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'transformer_path': 'distilbert-base-uncased',\n",
    "        'train_bert': 'all'\n",
    "    }\n",
    "\n",
    "model = HCRNSubtitles(\n",
    "    lr=0.0001,\n",
    "    model_kwargs=model_kwargs,\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/tgif-qa_frameqa/bert',\n",
    "    filename='tgif-bert-pretrained-1layer-train-all-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "wandb_logger = WandbLogger(name='HCRN-MSVD-bert',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc],\n",
    "    precision = 16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading appearance feature from data/tvqa/tvqa_appearance_feat.h5\n",
      "Loading subtitles from data/tvqa/tvqa_subtitles_splitted.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | criterion | CrossEntropyLoss | 0     \n",
      "1 | train_acc | Accuracy         | 0     \n",
      "2 | valid_acc | Accuracy         | 0     \n",
      "3 | test_acc  | Accuracy         | 0     \n",
      "4 | model     | HCRNNetworkTVQA  | 105 M \n",
      "-----------------------------------------------\n",
      "105 M     Trainable params\n",
      "0         Non-trainable params\n",
      "105 M     Total params\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading questions from data/tvqa/distilbert_question_embedding/tvqa_val_questions.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading questions from data/tvqa/distilbert_question_embedding/tvqa_train_questions.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40ee21cd20ed48d4b25bd80094df4134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8d127890155404f86cf8b2a0b627965",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model,tvqa_bert_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(verbose=False)\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## 2 Stream HCRN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import model.HCRN as HCRN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class HCRNSubtitles2Streams(pl.LightningModule):\n",
    "    def __init__(self, lr, model_kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.train_acc = pl.metrics.Accuracy()\n",
    "        self.valid_acc = pl.metrics.Accuracy()\n",
    "        self.test_acc = pl.metrics.Accuracy()\n",
    "        \n",
    "        self.model = HCRN.HCRNNetworkTVQA2Stream(**model_kwargs)\n",
    "        \n",
    "        self.bert_params = []\n",
    "        self.rest_params = []\n",
    "        for name, param in self.named_parameters():\n",
    "            if(name.startswith('model.linguistic_input_unit.bert')):\n",
    "                self.bert_params.append(param)\n",
    "            else:\n",
    "                self.rest_params.append(param)\n",
    "    \n",
    "    def forward(self,ans_candidates_tokens, ans_candidates_attention_mask, ans_candidates_token_type_ids,\n",
    "                video_appearance_feat, question_tokens,question_attention_masks,question_token_type_ids,\n",
    "               subtitles_tokens, subtitles_attention_mask, subtitles_token_type_ids):\n",
    "        return self.model(ans_candidates_tokens, ans_candidates_attention_mask,\n",
    "                          ans_candidates_token_type_ids, video_appearance_feat,\n",
    "                          question_tokens,question_attention_masks,question_token_type_ids,\n",
    "                         subtitles_tokens,subtitles_attention_mask, subtitles_token_type_ids)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer_model = optim.AdamW(self.rest_params, lr=self.lr)\n",
    "        optimizer_bert = optim.AdamW(self.bert_params, lr=1e-5)\n",
    "\n",
    "        return {'optimizer': optimizer_model},{'optimizer': optimizer_bert}\n",
    "   \n",
    "    def training_step(self,batch,batch_idx,optimizer_idx):\n",
    "        _, _, answers, *batch_input = batch\n",
    "        logits = self(*batch_input)\n",
    "        loss = self.criterion(logits, answers)\n",
    "        acc = self.train_acc(logits,answers)\n",
    "        self.log('step_loss',loss,prog_bar = True,logger=False)\n",
    "        return {'loss': loss,'n_samples':len(answers)}\n",
    "    \n",
    "    def training_epoch_end(self, training_step_outputs):\n",
    "        loss=0\n",
    "        n_samples = 0\n",
    "        for step_out in training_step_outputs[0]:\n",
    "            loss += step_out['loss']\n",
    "            n_samples += step_out['n_samples']\n",
    "        loss = loss/n_samples\n",
    "        self.log('train_loss',loss,logger=True)\n",
    "        self.log('train_acc',self.train_acc.compute(),logger=True)\n",
    "        \n",
    "    def validation_step(self,batch,batch_idx):\n",
    "        _, _, answers, *batch_input = batch\n",
    "        logits = self(*batch_input)\n",
    "        loss = self.criterion(logits, answers)\n",
    "        acc = self.valid_acc(logits,answers)\n",
    "        return {'val_loss': loss,'n_samples':len(answers)}\n",
    "    \n",
    "    def validation_epoch_end(self, val_step_outputs):\n",
    "        loss=0\n",
    "        n_samples = 0\n",
    "        for step_out in val_step_outputs:\n",
    "            loss += step_out['val_loss']\n",
    "            n_samples += step_out['n_samples']\n",
    "        loss = loss/n_samples\n",
    "        val_acc = self.valid_acc.compute()\n",
    "        self.log('val_acc',val_acc,prog_bar = True,logger=True)\n",
    "        self.log('val_loss',loss,logger=True)\n",
    "        \n",
    "    def test_step(self,batch,batch_idx):\n",
    "        _, _, answers, *batch_input = batch\n",
    "        logits = self(*batch_input)\n",
    "        acc = self.test_acc(logits,answers)\n",
    "    \n",
    "    def test_epoch_end(self,test_step_outputs):\n",
    "        test_acc = self.test_acc.compute()\n",
    "        print(f\"The test accuracy is {test_acc}\")\n",
    "        self.log('test_acc',test_acc,logger=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "tvqa_bert_data_module = TVQADataModule('data','tvqa',batch_size=25,text_embedding_model='distilbert',num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnicolas-dufour\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.15 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.12<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">tvqa subtitles 2 streams </strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/nicolas-dufour/video-qa-hcrn-recvis\" target=\"_blank\">https://wandb.ai/nicolas-dufour/video-qa-hcrn-recvis</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/nicolas-dufour/video-qa-hcrn-recvis/runs/2qjf0k8h\" target=\"_blank\">https://wandb.ai/nicolas-dufour/video-qa-hcrn-recvis/runs/2qjf0k8h</a><br/>\n",
       "                Run data is saved locally in <code>/home/jupyter/video-qa-recvis/wandb/run-20210125_123251-2qjf0k8h</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1>Run(2qjf0k8h)</h1><p></p><iframe src=\"https://wandb.ai/nicolas-dufour/video-qa-hcrn-recvis/runs/2qjf0k8h\" style=\"border:none;width:100%;height:400px\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7ff371806e90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"video-qa-hcrn-recvis\",name='tvqa subtitles 2 streams ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: Checkpoint directory models_checkpoints/tgif-qa_frameqa/bert exists and is not empty.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 10\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': tvqa_bert_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'transformer_path': 'distilbert-base-uncased',\n",
    "        'train_bert': 'all'\n",
    "    }\n",
    "\n",
    "model = HCRNSubtitles2Streams.load_from_checkpoint(\n",
    "    'models_checkpoints/tgif-qa_frameqa/bert/tvqa-2streams-train-all-epoch=04-val_acc=0.41.ckpt',\n",
    "    lr=0.00001,\n",
    "    model_kwargs=model_kwargs,\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/tgif-qa_frameqa/bert',\n",
    "    filename='tvqa-2streams-train-all-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "wandb_logger = WandbLogger(name='HCRN-MSVD-bert',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    resume_from_checkpoint = 'models_checkpoints/tgif-qa_frameqa/bert/tvqa-2streams-train-all-epoch=04-val_acc=0.41.ckpt',\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc],\n",
    "    precision = 16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading appearance feature from data/tvqa/tvqa_appearance_feat.h5\n",
      "Loading subtitles from data/tvqa/tvqa_subtitles_splitted.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type                   | Params\n",
      "-----------------------------------------------------\n",
      "0 | criterion | CrossEntropyLoss       | 0     \n",
      "1 | train_acc | Accuracy               | 0     \n",
      "2 | valid_acc | Accuracy               | 0     \n",
      "3 | test_acc  | Accuracy               | 0     \n",
      "4 | model     | HCRNNetworkTVQA2Stream | 88.0 M\n",
      "-----------------------------------------------------\n",
      "88.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "88.0 M    Total params\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading questions from data/tvqa/distilbert_question_embedding/tvqa_val_questions.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading questions from data/tvqa/distilbert_question_embedding/tvqa_train_questions.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c73ae30f37449b7a954d790d37e7bc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(model,tvqa_bert_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading questions from data/tvqa/distilbert_question_embedding/tvqa_test_questions.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "934fb32932fd4f0ca15b7549052075ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max="
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 12] Cannot allocate memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-959b1e9cfe13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'test_acc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtest_res\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self, model, test_dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m    752\u001b[0m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__test_given_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__test_using_best_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m__test_using_best_weights\u001b[0;34m(self, ckpt_path, test_dataloaders)\u001b[0m\n\u001b[1;32m    794\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PL_TESTING_MODE'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'1'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    797\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PL_TESTING_MODE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'on_fit_start'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pytorch_lightning/accelerators/gpu_accelerator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;31m# train or test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_or_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mtrain_or_test\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_or_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_test\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;31m# self.reset_test_dataloader(ref_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_test_evaluation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m             \u001b[0meval_loop_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_loop_results\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_evaluation\u001b[0;34m(self, test_mode, max_batches)\u001b[0m\n\u001b[1;32m    591\u001b[0m             \u001b[0mdl_max_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_batches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataloader_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_SingleProcessDataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_MultiProcessingDataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    719\u001b[0m             \u001b[0;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m             \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/process.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m                \u001b[0;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpopen_fork\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mSpawnProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseProcess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_launch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m_launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mparent_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 12] Cannot allocate memory"
     ]
    }
   ],
   "source": [
    "test_res = trainer.test(verbose=False)\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-6.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-6:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
