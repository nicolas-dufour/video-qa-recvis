{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import h5py\n",
    "import pytorch_lightning as pl\n",
    "import wandb\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import transformers\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "from DataLoader import VideoQADataModule\n",
    "import preprocess.msvd_text_prep as msvd_text_prep\n",
    "import preprocess.tgif_frameqa_text_prep as tgif_frameqa_text_prep\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# msvd_glove_data_module = VideoQADataModule('data','msvd-qa',batch_size=32,text_embedding_method='glove',num_workers=8)\n",
    "# msrvtt_glove_data_module = VideoQADataModule('data','msrvtt-qa',batch_size=32,text_embedding_method='glove',num_workers=8)\n",
    "# tgif_glove_data_module = VideoQADataModule('data','tgif-qa_frameqa',batch_size=32,text_embedding_method='glove',num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "tgifqa_frameqa_bert_data_module = VideoQADataModule('data','tgif-qa_frameqa',batch_size=32,text_embedding_model='bert')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "## Defining the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import model.HCRN as HCRN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class HCRN_glove(pl.LightningModule):\n",
    "    def __init__(self,glove_matrix,lr,model_kwargs,optimizer = 'AdamW'):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.train_acc = pl.metrics.Accuracy()\n",
    "        self.valid_acc = pl.metrics.Accuracy()\n",
    "        self.test_acc = pl.metrics.Accuracy()\n",
    "        \n",
    "        glove_matrix = torch.FloatTensor(glove_matrix)\n",
    "        self.model = HCRN.HCRNNetworkGlove(**model_kwargs)\n",
    "        with torch.no_grad():\n",
    "            self.model.linguistic_input_unit.encoder_embed.weight.set_(glove_matrix)\n",
    "    \n",
    "    def forward(self,ans_candidates, ans_candidates_len, video_appearance_feat, video_motion_feat, question,\n",
    "                question_len):\n",
    "        return self.model(ans_candidates, ans_candidates_len, video_appearance_feat, video_motion_feat, question,\n",
    "                question_len)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        if(self.optimizer == 'Adam'):\n",
    "            optimizer = optim.Adam(self.parameters(), lr=self.lr)\n",
    "        elif(self.optimizer == 'AdamW'):\n",
    "            optimizer = optim.AdamW(self.parameters(), lr=self.lr)\n",
    "        else:\n",
    "            raise \"Optimizer not supported\"\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer,10,gamma=0.5)\n",
    "        return [optimizer],[scheduler]\n",
    "   \n",
    "    def training_step(self,batch,batch_idx):\n",
    "        _, _, answers, *batch_input = batch\n",
    "        logits = self(*batch_input)\n",
    "        loss = self.criterion(logits, answers)\n",
    "        acc = self.train_acc(logits,answers)\n",
    "        self.log('step_loss',loss,prog_bar = True,logger=False)\n",
    "        return {'loss': loss,'n_samples':len(answers)}\n",
    "    \n",
    "    def training_epoch_end(self, training_step_outputs):\n",
    "        loss=0\n",
    "        n_samples = 0\n",
    "        for step_out in training_step_outputs:\n",
    "            loss += step_out['loss']\n",
    "            n_samples += step_out['n_samples']\n",
    "        loss = loss/n_samples\n",
    "        self.log('train_loss',loss,logger=True)\n",
    "        self.log('train_acc',self.train_acc.compute(),logger=True)\n",
    "        \n",
    "    def validation_step(self,batch,batch_idx):\n",
    "        _, _, answers, *batch_input = batch\n",
    "        logits = self(*batch_input)\n",
    "        loss = self.criterion(logits, answers)\n",
    "        acc = self.valid_acc(logits,answers)\n",
    "        return {'val_loss': loss,'n_samples':len(answers)}\n",
    "    \n",
    "    def validation_epoch_end(self, val_step_outputs):\n",
    "        loss=0\n",
    "        n_samples = 0\n",
    "        for step_out in val_step_outputs:\n",
    "            loss += step_out['val_loss']\n",
    "            n_samples += step_out['n_samples']\n",
    "        loss = loss/n_samples\n",
    "        val_acc = self.valid_acc.compute()\n",
    "        self.log('val_acc',val_acc,prog_bar = True,logger=True)\n",
    "        self.log('val_loss',loss,logger=True)\n",
    "        \n",
    "    def test_step(self,batch,batch_idx):\n",
    "        _, _, answers, *batch_input = batch\n",
    "        logits = self(*batch_input).detach()\n",
    "        acc = self.test_acc(logits,answers)\n",
    "    \n",
    "    def test_epoch_end(self,test_step_outputs):\n",
    "        test_acc = self.test_acc.compute()\n",
    "        print(f\"The test accuracy is {test_acc}\")\n",
    "        self.log('test_acc',test_acc,logger=True)\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "## Recreating papers results on MSVD-QA, MSRVTT-QA, TGIF-QA_FrameQA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "### MSVD-QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 1\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': msvd_glove_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'word_dim': 300,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': msvd_glove_data_module.vocab\n",
    "    }\n",
    "model = HCRN_glove(\n",
    "    glove_matrix=msvd_glove_data_module.glove_matrix,\n",
    "    lr=0.0001,\n",
    "    model_kwargs=model_kwargs,\n",
    "    optimizer='Adam'\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/msvd/baseline',\n",
    "    filename='msvd-base-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "wandb_logger = WandbLogger(name='HCRN-MSVD-base',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,msvd_glove_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "### MSRVTT-QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 25\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': msrvtt_glove_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'word_dim': 300,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': msrvtt_glove_data_module.vocab\n",
    "    }\n",
    "model = HCRN_glove(\n",
    "    glove_matrix=msrvtt_glove_data_module.glove_matrix,\n",
    "    lr=0.0001, \n",
    "    model_kwargs=model_kwargs, \n",
    "    optimizer='Adam'\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/msrvtt/baseline',\n",
    "    filename='msrvtt-base-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "wandb_logger = WandbLogger(name='HCRN-MSRVTT-base',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,msrvtt_glove_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(verbose=False)\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "### TGIF-QA FrameQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 25\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': tgif_glove_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'word_dim': 300,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': tgif_glove_data_module.vocab\n",
    "    }\n",
    "model = HCRN_glove(\n",
    "    glove_matrix=tgif_glove_data_module.glove_matrix,\n",
    "    lr=0.0001, \n",
    "    model_kwargs=model_kwargs, \n",
    "    optimizer='Adam'\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/tgif-qa_frameqa/baseline',\n",
    "    filename='tgif-qa_frameqa-base-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "wandb_logger = WandbLogger(name='HCRN-MSRVTT-base',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,tgif_glove_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(verbose=False)\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "## Improving using AdamW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### MSVD-QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 15\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': msvd_glove_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'word_dim': 300,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': msvd_glove_data_module.vocab\n",
    "    }\n",
    "model = HCRN_glove(\n",
    "    glove_matrix=msvd_glove_data_module.glove_matrix,\n",
    "    lr=0.0001,\n",
    "    model_kwargs=model_kwargs,\n",
    "    optimizer='AdamW'\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/msvd/baseline',\n",
    "    filename='msvd-adamw-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "wandb_logger = WandbLogger(name='HCRN-MSVD-base',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,msvd_glove_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(verbose=False)\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### MSRVTT-QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 15\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': msrvtt_glove_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'word_dim': 300,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': msrvtt_glove_data_module.vocab\n",
    "    }\n",
    "model = HCRN_glove(\n",
    "    glove_matrix=msrvtt_glove_data_module.glove_matrix,\n",
    "    lr=0.0001, \n",
    "    model_kwargs=model_kwargs, \n",
    "    optimizer='AdamW'\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/msrvtt/baseline',\n",
    "    filename='msrvtt-adamw-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "wandb_logger = WandbLogger(name='HCRN-MSRVTT-base',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,msrvtt_glove_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(model,msrvtt_glove_data_module.test_dataloader())\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save('models_checkpoints/msrvtt/baseline/msrvtt-adamw-epoch=09-val_acc=0.35.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### TGIF-QA FrameQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 15\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': tgif_glove_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'word_dim': 300,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': tgif_glove_data_module.vocab\n",
    "    }\n",
    "model = HCRN_glove.load_from_checkpoint(\n",
    "    'models_checkpoints/tgif-qa_frameqa/baseline/tgif-qa_frameqa-adamW-epoch=07-val_acc=0.56.ckpt',\n",
    "    glove_matrix=tgif_glove_data_module.glove_matrix,\n",
    "    lr=0.0001, \n",
    "    model_kwargs=model_kwargs, \n",
    "    optimizer='AdamW'\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/tgif-qa_frameqa/baseline',\n",
    "    filename='tgif-qa_frameqa-base-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "wandb_logger = WandbLogger(name='HCRN-MSRVTT-base',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,tgif_glove_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(model,test_dataloaders = tgif_glove_data_module.test_dataloader())\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "## Create Bert Questions datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### MSVD-QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.read_json('data/msvd-qa/raw_questions/train_qa.json').to_csv('data/msvd-qa/raw_questions/train_qa.csv',sep= '\\t')\n",
    "pd.read_json('data/msvd-qa/raw_questions/val_qa.json').to_csv('data/msvd-qa/raw_questions/val_qa.csv',sep= '\\t')\n",
    "pd.read_json('data/msvd-qa/raw_questions/test_qa.json').to_csv('data/msvd-qa/raw_questions/test_qa.csv',sep= '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "msvd_text_prep.create_vocab('data/msvd-qa/raw_questions/train_qa.json',vocab_path='data/msvd-qa/bert_question_embedding/msvd-qa_vocab_bert.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "msvd_text_prep.process_questions(\n",
    "    train_csv ='data/msvd-qa/raw_questions/train_qa.csv', \n",
    "    val_csv = 'data/msvd-qa/raw_questions/val_qa.csv',\n",
    "    test_csv = 'data/msvd-qa/raw_questions/test_qa.csv',\n",
    "    fine_tune_out_path ='data/msvd-qa/bert_question_embedding/question_finetuned_model',\n",
    "    train_output = 'data/msvd-qa/bert_question_embedding/msvd-qa_train_questions.pt',\n",
    "    val_output = 'data/msvd-qa/bert_question_embedding/msvd-qa_val_questions.pt',\n",
    "    test_output = 'data/msvd-qa/bert_question_embedding/msvd-qa_test_questions.pt',\n",
    "    vocab_path='data/msvd-qa/bert_question_embedding/msvd-qa_vocab_bert.json'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### TGIFQA FrameQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "tgif_frameqa_text_prep.create_vocab('data/tgif-qa_frameqa/raw_questions/train_qa.csv',vocab_path='data/tgif-qa_frameqa/bert_question_embedding/tgif-qa_frameqa_vocab_bert.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "tgif_frameqa_text_prep.process_questions(\n",
    "    train_csv ='data/tgif-qa_frameqa/raw_questions/train_qa.csv', \n",
    "    val_csv = 'data/tgif-qa_frameqa/raw_questions/val_qa.csv',\n",
    "    test_csv = 'data/tgif-qa_frameqa/raw_questions/test_qa.csv',\n",
    "    fine_tune_out_path ='data/tgif-qa_frameqa/bert_question_embedding/question_finetuned_model',\n",
    "    train_output = 'data/tgif-qa_frameqa/bert_question_embedding/tgif-qa_frameqa_train_questions.pt',\n",
    "    val_output = 'data/tgif-qa_frameqa/bert_question_embedding/tgif-qa_frameqa_val_questions.pt',\n",
    "    test_output = 'data/tgif-qa_frameqa/bert_question_embedding/tgif-qa_frameqa_test_questions.pt',\n",
    "    vocab_path='data/tgif-qa_frameqa/bert_question_embedding/tgif-qa_frameqa_vocab_bert.json'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "## Bert text embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import model.HCRN as HCRN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class HCRNBert(pl.LightningModule):\n",
    "    def __init__(self, lr, model_kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.train_acc = pl.metrics.Accuracy()\n",
    "        self.valid_acc = pl.metrics.Accuracy()\n",
    "        self.test_acc = pl.metrics.Accuracy()\n",
    "        \n",
    "        self.model = HCRN.HCRNNetworkBert(**model_kwargs)\n",
    "        \n",
    "        self.bert_params = []\n",
    "        self.rest_params = []\n",
    "        for name, param in self.named_parameters():\n",
    "            if(name.startswith('model.linguistic_input_unit.bert')):\n",
    "                self.bert_params.append(param)\n",
    "            else:\n",
    "                self.rest_params.append(param)\n",
    "    \n",
    "    def forward(self,ans_candidates, ans_candidates_len, video_appearance_feat, video_motion_feat, question_tokens,question_attention_masks,question_token_type_ids):\n",
    "        return self.model(ans_candidates, ans_candidates_len, video_appearance_feat, video_motion_feat, question_tokens,question_attention_masks,question_token_type_ids)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer_model = optim.AdamW(self.rest_params, lr=self.lr)\n",
    "        optimizer_bert = optim.AdamW(self.bert_params, lr=1e-5)\n",
    "\n",
    "        return {'optimizer': optimizer_model},{'optimizer': optimizer_bert}\n",
    "   \n",
    "    def training_step(self,batch,batch_idx,optimizer_idx):\n",
    "        _, _, answers, *batch_input = batch\n",
    "        logits = self(*batch_input)\n",
    "        loss = self.criterion(logits, answers)\n",
    "        acc = self.train_acc(logits,answers)\n",
    "        self.log('step_loss',loss,prog_bar = True,logger=False)\n",
    "        return {'loss': loss,'n_samples':len(answers)}\n",
    "    \n",
    "    def training_epoch_end(self, training_step_outputs):\n",
    "        loss=0\n",
    "        n_samples = 0\n",
    "        for step_out in training_step_outputs[0]:\n",
    "            loss += step_out['loss']\n",
    "            n_samples += step_out['n_samples']\n",
    "        loss = loss/n_samples\n",
    "        self.log('train_loss',loss,logger=True)\n",
    "        self.log('train_acc',self.train_acc.compute(),logger=True)\n",
    "        \n",
    "    def validation_step(self,batch,batch_idx):\n",
    "        _, _, answers, *batch_input = batch\n",
    "        logits = self(*batch_input)\n",
    "        loss = self.criterion(logits, answers)\n",
    "        acc = self.valid_acc(logits,answers)\n",
    "        return {'val_loss': loss,'n_samples':len(answers)}\n",
    "    \n",
    "    def validation_epoch_end(self, val_step_outputs):\n",
    "        loss=0\n",
    "        n_samples = 0\n",
    "        for step_out in val_step_outputs:\n",
    "            loss += step_out['val_loss']\n",
    "            n_samples += step_out['n_samples']\n",
    "        loss = loss/n_samples\n",
    "        val_acc = self.valid_acc.compute()\n",
    "        self.log('val_acc',val_acc,prog_bar = True,logger=True)\n",
    "        self.log('val_loss',loss,logger=True)\n",
    "        \n",
    "    def test_step(self,batch,batch_idx):\n",
    "        _, _, answers, *batch_input = batch\n",
    "        logits = self(*batch_input)\n",
    "        acc = self.test_acc(logits,answers)\n",
    "    \n",
    "    def test_epoch_end(self,test_step_outputs):\n",
    "        test_acc = self.test_acc.compute()\n",
    "        print(f\"The test accuracy is {test_acc}\")\n",
    "        self.log('test_acc',test_acc,logger=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "### No training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Bert uncased single layer embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"video-qa-hcrn-recvis\",name='bert fextract hf-model single layer embed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 25\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': msvd_bert_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': msvd_bert_data_module.vocab,\n",
    "        'bert_path': 'bert-base-uncased',\n",
    "        'mult_embedding': False\n",
    "    }\n",
    "model = HCRNBert(\n",
    "    lr=0.0001,\n",
    "    model_kwargs=model_kwargs\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/tgif-qa_frameqa/bert',\n",
    "    filename='tgif-bert-pretrained-1layer-nograd-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "wandb_logger = WandbLogger(name='HCRN-MSVD-bert',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,msvd_bert_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(verbose=False)\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### 4 Last layers bert base uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"video-qa-hcrn-recvis\",name='bert fextract hf-model 4 layer embed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 25\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': msvd_bert_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': msvd_bert_data_module.vocab,\n",
    "        'bert_path': 'bert-base-uncased',\n",
    "        'mult_embedding': True\n",
    "    }\n",
    "model = HCRNBert(\n",
    "    lr=0.0001,\n",
    "    model_kwargs=model_kwargs,\n",
    "    optimizer='AdamW'\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/tgif-qa_frameqa/bert',\n",
    "    filename='tgif-bert-pretrained-4layer-nograd-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "wandb_logger = WandbLogger(name='HCRN-MSVD-bert',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,msvd_bert_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(verbose=False)\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Finetuned on questions 1 layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"video-qa-hcrn-recvis\",name='bert fextract question-tuned-model single layer embed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 25\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': msvd_bert_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': msvd_bert_data_module.vocab,\n",
    "        'bert_path': 'data/tgif-qa_frameqa/bert_question_embedding/question_finetuned_model',\n",
    "        'mult_embedding': False\n",
    "    }\n",
    "model = HCRNBert(\n",
    "    lr=0.0001,\n",
    "    model_kwargs=model_kwargs,\n",
    "    optimizer='AdamW'\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/tgif-qa_frameqa/bert',\n",
    "    filename='tgif-bert-finetuned-1layer-nograd-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "wandb_logger = WandbLogger(name='HCRN-MSVD-bert',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,msvd_bert_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(verbose=False)\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Finetuned on questions 4layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"video-qa-hcrn-recvis\",name='bert fextract question-tuned-model single layer embed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 25\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': msvd_bert_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': msvd_bert_data_module.vocab,\n",
    "        'bert_path': 'data/tgif-qa_frameqa/bert_question_embedding/question_finetuned_model',\n",
    "        'mult_embedding': True\n",
    "    }\n",
    "model = HCRNBert(\n",
    "    lr=0.0001,\n",
    "    model_kwargs=model_kwargs,\n",
    "    optimizer='AdamW'\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/tgif-qa_frameqa/bert',\n",
    "    filename='tgif-bert-finetuned-4layer-nograd-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "wandb_logger = WandbLogger(name='HCRN-MSVD-bert',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,msvd_bert_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(verbose=False)\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Training Bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "#### Train All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"video-qa-hcrn-recvis\",name='tgif-qa bert train all hf-model pooler')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 25\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': tgifqa_frameqa_bert_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': tgifqa_frameqa_bert_data_module.vocab,\n",
    "        'bert_path': 'bert-base-uncased',\n",
    "        'train_bert': 'All'\n",
    "    }\n",
    "model = HCRNBert(\n",
    "    lr=0.0001,\n",
    "    model_kwargs=model_kwargs,\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/tgif-qa_frameqa/bert',\n",
    "    filename='tgif-bert-pretrained-1layer-train-all-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "lr_logger_callback = pl.callbacks.LearningRateMonitor(logging_interval='step')\n",
    "wandb_logger = WandbLogger(name='HCRN-MSVD-bert',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc,lr_logger_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,tgifqa_frameqa_bert_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(ckpt_path='models_checkpoints/tgif-qa_frameqa/bert/tgif-bert-pretrained-1layer-train-all-epoch=08-val_acc=0.55.ckpt',verbose=False)\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "#### Train 4 last layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"video-qa-hcrn-recvis\",name='tgif-qa bert train 4 last hf-model pooler')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 25\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': tgifqa_frameqa_bert_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': tgifqa_frameqa_bert_data_module.vocab,\n",
    "        'bert_path': 'bert-base-uncased',\n",
    "        'train_bert': 'last-4'\n",
    "    }\n",
    "model = HCRNBert(\n",
    "    nb_train_steps = tgifqa_frameqa_bert_data_module.number_training_steps(),\n",
    "    lr=0.0001,\n",
    "    max_epochs=max_epochs,\n",
    "    model_kwargs=model_kwargs,\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/tgif-qa_frameqa/bert',\n",
    "    filename='tgif-bert-pretrained-1layer-train-all-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "lr_logger_callback = pl.callbacks.LearningRateMonitor(logging_interval='epoch')\n",
    "wandb_logger = WandbLogger(name='HCRN-MSVD-bert',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc,lr_logger_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,tgifqa_frameqa_bert_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(verbose=False)\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "#### Train 2 last layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"video-qa-hcrn-recvis\",name='tgif-qa bert train 4 last hf-model pooler')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 25\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': tgifqa_frameqa_bert_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': tgifqa_frameqa_bert_data_module.vocab,\n",
    "        'bert_path': 'bert-base-uncased',\n",
    "        'train_bert': 'last-4'\n",
    "    }\n",
    "model = HCRNBert(\n",
    "    nb_train_steps = tgifqa_frameqa_bert_data_module.number_training_steps(),\n",
    "    lr=0.0001,\n",
    "    max_epochs=max_epochs,\n",
    "    model_kwargs=model_kwargs,\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/tgif-qa_frameqa/bert',\n",
    "    filename='tgif-bert-pretrained-1layer-train-all-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "lr_logger_callback = pl.callbacks.LearningRateMonitor(logging_interval='epoch')\n",
    "wandb_logger = WandbLogger(name='HCRN-MSVD-bert',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc,lr_logger_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,tgifqa_frameqa_bert_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(verbose=False)\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "## Roberta Text Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Train All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"video-qa-hcrn-recvis\",name='tgif-qa distillbert train all hf-model pooler')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 25\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': tgifqa_frameqa_bert_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': tgifqa_frameqa_bert_data_module.vocab,\n",
    "        'transformer_path': 'distilbert-base-uncased',\n",
    "        'train_bert': 'All'\n",
    "    }\n",
    "model = HCRNBert(\n",
    "    lr=0.0001,\n",
    "    model_kwargs=model_kwargs,\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/tgif-qa_frameqa/bert',\n",
    "    filename='tgif-distillbert-pretrained-1layer-train-all-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "lr_logger_callback = pl.callbacks.LearningRateMonitor(logging_interval='step')\n",
    "wandb_logger = WandbLogger(name='HCRN-MSVD-distillbert',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc,lr_logger_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,tgifqa_frameqa_bert_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(verbose=False)\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from transformers import DistilBertModel\n",
    "DistilBertModel.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "## Bert Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import model.HCRN as HCRN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class HCRNBertAblation(pl.LightningModule):\n",
    "    def __init__(self, lr, model_kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.train_acc = pl.metrics.Accuracy()\n",
    "        self.valid_acc = pl.metrics.Accuracy()\n",
    "        self.test_acc = pl.metrics.Accuracy()\n",
    "        \n",
    "        self.model = HCRN.HCRNNetworkBertAblation(**model_kwargs)\n",
    "        \n",
    "        self.bert_params = []\n",
    "        self.rest_params = []\n",
    "        for name, param in self.named_parameters():\n",
    "            if(name.startswith('model.linguistic_input_unit.bert')):\n",
    "                self.bert_params.append(param)\n",
    "            else:\n",
    "                self.rest_params.append(param)\n",
    "    \n",
    "    def forward(self,ans_candidates, ans_candidates_len, video_appearance_feat, video_motion_feat, question_tokens,question_attention_masks,question_token_type_ids):\n",
    "        return self.model(ans_candidates, ans_candidates_len, video_appearance_feat, video_motion_feat, question_tokens,question_attention_masks,question_token_type_ids)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer_model = optim.AdamW(self.rest_params, lr=self.lr)\n",
    "        optimizer_bert = optim.AdamW(self.bert_params, lr=1e-5)\n",
    "        return {'optimizer': optimizer_model},{'optimizer': optimizer_bert}\n",
    "   \n",
    "    def training_step(self,batch,batch_idx,optimizer_idx):\n",
    "        _, _, answers, *batch_input = batch\n",
    "        logits = self(*batch_input)\n",
    "        loss = self.criterion(logits, answers)\n",
    "        acc = self.train_acc(logits,answers)\n",
    "        self.log('step_loss',loss,prog_bar = True,logger=False)\n",
    "        return {'loss': loss,'n_samples':len(answers)}\n",
    "    \n",
    "    def training_epoch_end(self, training_step_outputs):\n",
    "        loss=0\n",
    "        n_samples = 0\n",
    "        for step_out in training_step_outputs[0]:\n",
    "            loss += step_out['loss']\n",
    "            n_samples += step_out['n_samples']\n",
    "        loss = loss/n_samples\n",
    "        self.log('train_loss',loss,logger=True)\n",
    "        self.log('train_acc',self.train_acc.compute(),logger=True)\n",
    "        \n",
    "    def validation_step(self,batch,batch_idx):\n",
    "        _, _, answers, *batch_input = batch\n",
    "        logits = self(*batch_input)\n",
    "        loss = self.criterion(logits, answers)\n",
    "        acc = self.valid_acc(logits,answers)\n",
    "        return {'val_loss': loss,'n_samples':len(answers)}\n",
    "    \n",
    "    def validation_epoch_end(self, val_step_outputs):\n",
    "        loss=0\n",
    "        n_samples = 0\n",
    "        for step_out in val_step_outputs:\n",
    "            loss += step_out['val_loss']\n",
    "            n_samples += step_out['n_samples']\n",
    "        loss = loss/n_samples\n",
    "        val_acc = self.valid_acc.compute()\n",
    "        self.log('val_acc',val_acc,prog_bar = True,logger=True)\n",
    "        self.log('val_loss',loss,logger=True)\n",
    "        \n",
    "    def test_step(self,batch,batch_idx):\n",
    "        _, _, answers, *batch_input = batch\n",
    "        logits = self(*batch_input)\n",
    "        acc = self.test_acc(logits,answers)\n",
    "    \n",
    "    def test_epoch_end(self,test_step_outputs):\n",
    "        test_acc = self.test_acc.compute()\n",
    "        print(f\"The test accuracy is {test_acc}\")\n",
    "        self.log('test_acc',test_acc,logger=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Motion Ablation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Full Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"video-qa-hcrn-recvis\",name='tgif-qa bert train all hf-model pooler no-motion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 15\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': tgifqa_frameqa_bert_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': tgifqa_frameqa_bert_data_module.vocab,\n",
    "        'transformer_path': 'bert-base-uncased',\n",
    "        'train_bert': 'All',\n",
    "        'ablated_features':['clip_motion','video_motion']\n",
    "    }\n",
    "model = HCRNBertAblation(\n",
    "    lr=0.0001,\n",
    "    model_kwargs=model_kwargs,\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/tgif-qa_frameqa/bert',\n",
    "    filename='tgif-bert-pretrained-1layer-train-all-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "lr_logger_callback = pl.callbacks.LearningRateMonitor(logging_interval='step')\n",
    "wandb_logger = WandbLogger(name='HCRN-MSVD-bert',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc,lr_logger_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,tgifqa_frameqa_bert_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(verbose=False)\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Video level Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"video-qa-hcrn-recvis\",name='tgif-qa bert train all hf-model pooler no-video-motion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 15\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': tgifqa_frameqa_bert_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': tgifqa_frameqa_bert_data_module.vocab,\n",
    "        'transformer_path': 'bert-base-uncased',\n",
    "        'train_bert': 'All',\n",
    "        'ablated_features':['video_motion']\n",
    "    }\n",
    "model = HCRNBertAblation(\n",
    "    lr=0.0001,\n",
    "    model_kwargs=model_kwargs,\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/tgif-qa_frameqa/bert',\n",
    "    filename='tgif-bert-pretrained-1layer-train-all-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "lr_logger_callback = pl.callbacks.LearningRateMonitor(logging_interval='step')\n",
    "wandb_logger = WandbLogger(name='HCRN-MSVD-bert',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc,lr_logger_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,tgifqa_frameqa_bert_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(verbose=False)\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Clip level Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"video-qa-hcrn-recvis\",name='tgif-qa bert train all hf-model pooler no-clip-motion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 15\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': tgifqa_frameqa_bert_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': tgifqa_frameqa_bert_data_module.vocab,\n",
    "        'transformer_path': 'bert-base-uncased',\n",
    "        'train_bert': 'All',\n",
    "        'ablated_features':['clip_motion']\n",
    "    }\n",
    "model = HCRNBertAblation(\n",
    "    lr=0.0001,\n",
    "    model_kwargs=model_kwargs,\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/tgif-qa_frameqa/bert',\n",
    "    filename='tgif-bert-pretrained-1layer-train-all-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "lr_logger_callback = pl.callbacks.LearningRateMonitor(logging_interval='step')\n",
    "wandb_logger = WandbLogger(name='HCRN-MSVD-bert',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc,lr_logger_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,tgifqa_frameqa_bert_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(verbose=False)\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Question Ablation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Full Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"video-qa-hcrn-recvis\",name='tgif-qa bert train all hf-model pooler no-question-features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 15\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': tgifqa_frameqa_bert_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': tgifqa_frameqa_bert_data_module.vocab,\n",
    "        'transformer_path': 'bert-base-uncased',\n",
    "        'train_bert': 'All',\n",
    "        'ablated_features':['clip_question','video_question']\n",
    "    }\n",
    "model = HCRNBertAblation(\n",
    "    lr=0.0001,\n",
    "    model_kwargs=model_kwargs,\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/tgif-qa_frameqa/bert',\n",
    "    filename='tgif-bert-pretrained-1layer-train-all-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "lr_logger_callback = pl.callbacks.LearningRateMonitor(logging_interval='step')\n",
    "wandb_logger = WandbLogger(name='HCRN-MSVD-bert',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc,lr_logger_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,tgifqa_frameqa_bert_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(verbose=False)\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Video level Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"video-qa-hcrn-recvis\",name='tgif-qa bert train all hf-model pooler no-video-question-features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 15\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': tgifqa_frameqa_bert_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': tgifqa_frameqa_bert_data_module.vocab,\n",
    "        'transformer_path': 'bert-base-uncased',\n",
    "        'train_bert': 'All',\n",
    "        'ablated_features':['video_question']\n",
    "    }\n",
    "model = HCRNBertAblation(\n",
    "    lr=0.0001,\n",
    "    model_kwargs=model_kwargs,\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/tgif-qa_frameqa/bert',\n",
    "    filename='tgif-bert-pretrained-1layer-train-all-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "lr_logger_callback = pl.callbacks.LearningRateMonitor(logging_interval='step')\n",
    "wandb_logger = WandbLogger(name='HCRN-MSVD-bert',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc,lr_logger_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,tgifqa_frameqa_bert_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(verbose=False)\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Clip level Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"video-qa-hcrn-recvis\",name='tgif-qa bert train all hf-model pooler no-clip-question-features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 15\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': tgifqa_frameqa_bert_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': tgifqa_frameqa_bert_data_module.vocab,\n",
    "        'transformer_path': 'bert-base-uncased',\n",
    "        'train_bert': 'All',\n",
    "        'ablated_features':['clip_question']\n",
    "    }\n",
    "model = HCRNBertAblation(\n",
    "    lr=0.0001,\n",
    "    model_kwargs=model_kwargs,\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/tgif-qa_frameqa/bert',\n",
    "    filename='tgif-bert-pretrained-1layer-train-all-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "lr_logger_callback = pl.callbacks.LearningRateMonitor(logging_interval='step')\n",
    "wandb_logger = WandbLogger(name='HCRN-MSVD-bert',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc,lr_logger_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,tgifqa_frameqa_bert_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(verbose=False)\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### No appareance features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### No motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"video-qa-hcrn-recvis\",name='tgif-qa bert train all hf-model pooler no-visual-features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 15\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': tgifqa_frameqa_bert_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': tgifqa_frameqa_bert_data_module.vocab,\n",
    "        'transformer_path': 'bert-base-uncased',\n",
    "        'train_bert': 'All',\n",
    "        'ablated_features':['clip_motion','video_motion','video_appearance_ablation']\n",
    "    }\n",
    "model = HCRNBertAblation(\n",
    "    lr=0.0001,\n",
    "    model_kwargs=model_kwargs,\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/tgif-qa_frameqa/bert',\n",
    "    filename='tgif-bert-pretrained-1layer-train-all-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "lr_logger_callback = pl.callbacks.LearningRateMonitor(logging_interval='step')\n",
    "wandb_logger = WandbLogger(name='HCRN-MSVD-bert',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc,lr_logger_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,tgifqa_frameqa_bert_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(verbose=False)\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Clip level Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"video-qa-hcrn-recvis\",name='tgif-qa bert train all hf-model pooler no-appearance-features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "max_epochs = 15\n",
    "\n",
    "model_kwargs = {\n",
    "        'question_type': tgifqa_frameqa_bert_data_module.question_type,\n",
    "        'vision_dim': 2048,\n",
    "        'module_dim': 512,\n",
    "        'k_max_frame_level': 16,\n",
    "        'k_max_clip_level': 8,\n",
    "        'spl_resolution': 1,\n",
    "        'vocab': tgifqa_frameqa_bert_data_module.vocab,\n",
    "        'transformer_path': 'bert-base-uncased',\n",
    "        'train_bert': 'All',\n",
    "        'ablated_features':['video_appearance_ablation']\n",
    "    }\n",
    "model = HCRNBertAblation(\n",
    "    lr=0.0001,\n",
    "    model_kwargs=model_kwargs,\n",
    ")\n",
    "\n",
    "checkpoint_callback_val_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='models_checkpoints/tgif-qa_frameqa/bert',\n",
    "    filename='tgif-bert-pretrained-1layer-train-all-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "lr_logger_callback = pl.callbacks.LearningRateMonitor(logging_interval='step')\n",
    "wandb_logger = WandbLogger(name='HCRN-MSVD-bert',project='video-qa-hcrn-recvis')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    logger = wandb_logger,\n",
    "    callbacks =[checkpoint_callback_val_acc,lr_logger_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model,tgifqa_frameqa_bert_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_res = trainer.test(verbose=False)\n",
    "wandb.log({'test_acc':test_res[0]['test_acc']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "wandb.save(trainer.checkpoint_callback.best_model_path)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-6.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-6:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
